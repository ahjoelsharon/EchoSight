<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AI Smart Assistive Glasses | Advanced Engineering Project</title>

  <!-- Google Font -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet">

  <style>
    :root {
      --bg: #0b0f1a;
      --bg-soft: #12182b;
      --primary: #4fd1c5;
      --secondary: #60a5fa;
      --text: #e5e7eb;
      --muted: #9ca3af;
      --card: rgba(255,255,255,0.04);
      --border: rgba(255,255,255,0.08);
      --glow: rgba(79,209,197,0.35);
    }

    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
      font-family: 'Inter', sans-serif;
    }

    body {
      background: radial-gradient(circle at top, #10162b, var(--bg));
      color: var(--text);
      line-height: 1.7;
      overflow-x: hidden;
    }

    /* ---------- Animations ---------- */
    @keyframes fadeUp {
      from { opacity: 0; transform: translateY(30px); }
      to { opacity: 1; transform: translateY(0); }
    }

    @keyframes glowPulse {
      0% { box-shadow: 0 0 0px var(--glow); }
      50% { box-shadow: 0 0 25px var(--glow); }
      100% { box-shadow: 0 0 0px var(--glow); }
    }

    /* ---------- Header ---------- */
    header {
      min-height: 100vh;
      display: flex;
      align-items: center;
      justify-content: center;
      text-align: center;
      padding: 60px 20px;
      animation: fadeUp 1.2s ease forwards;
    }

    header h1 {
      font-size: 3.2rem;
      font-weight: 700;
      background: linear-gradient(90deg, var(--primary), var(--secondary));
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      margin-bottom: 20px;
    }

    header p {
      max-width: 820px;
      margin: auto;
      color: var(--muted);
      font-size: 1.15rem;
    }

    /* ---------- Navigation ---------- */
    nav {
      position: sticky;
      top: 0;
      backdrop-filter: blur(12px);
      background: rgba(10,15,30,0.6);
      border-bottom: 1px solid var(--border);
      z-index: 1000;
    }

    nav ul {
      display: flex;
      justify-content: center;
      flex-wrap: wrap;
      list-style: none;
      padding: 12px 10px;
    }

    nav ul li {
      margin: 8px 18px;
    }

    nav ul li a {
      color: var(--text);
      text-decoration: none;
      font-weight: 500;
      position: relative;
    }

    nav ul li a::after {
      content: "";
      position: absolute;
      left: 0;
      bottom: -6px;
      width: 0;
      height: 2px;
      background: var(--primary);
      transition: width 0.3s ease;
    }

    nav ul li a:hover::after {
      width: 100%;
    }

    /* ---------- Sections ---------- */
    section {
      padding: 100px 20px;
      max-width: 1200px;
      margin: auto;
      animation: fadeUp 1.1s ease forwards;
    }

    section h2 {
      text-align: center;
      font-size: 2.4rem;
      margin-bottom: 50px;
      color: var(--primary);
    }

    /* ---------- Cards ---------- */
    .grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
      gap: 30px;
    }

    .card {
      background: var(--card);
      border: 1px solid var(--border);
      padding: 30px;
      border-radius: 18px;
      transition: transform 0.4s ease, box-shadow 0.4s ease;
    }

    .card:hover {
      transform: translateY(-8px) scale(1.01);
      box-shadow: 0 0 30px rgba(79,209,197,0.15);
    }

    .card h3 {
      color: var(--secondary);
      margin-bottom: 10px;
    }

    /* ---------- Tables ---------- */
    table {
      width: 100%;
      border-collapse: collapse;
      overflow: hidden;
      border-radius: 14px;
      border: 1px solid var(--border);
    }

    table th, table td {
      padding: 16px;
      border-bottom: 1px solid var(--border);
    }

    table th {
      background: rgba(79,209,197,0.1);
      color: var(--primary);
      text-align: left;
    }

    /* ---------- Highlight ---------- */
    .highlight {
      color: var(--primary);
      font-weight: 600;
    }

    /* ---------- Footer ---------- */
    footer {
      background: linear-gradient(180deg, transparent, #060912);
      text-align: center;
      padding: 60px 20px;
      color: var(--muted);
    }

    footer p {
      max-width: 900px;
      margin: auto;
    }

  </style>
</head>
<body>

<header>
  <div>
    <h1>AI-Powered Smart Assistive Glasses</h1>
    <p>
      A future-ready engineering innovation that leverages artificial intelligence, edge computing,
      and simulation-driven development to transform real-world vision into meaningful audio guidance
      for visually impaired individuals.
    </p>
    <div style="margin-top:40px; display:flex; justify-content:center;">
      <svg width="520" height="220" viewBox="0 0 520 220" xmlns="http://www.w3.org/2000/svg">
        <defs>
          <linearGradient id="g1" x1="0" y1="0" x2="1" y2="1">
            <stop offset="0%" stop-color="#4fd1c5"/>
            <stop offset="100%" stop-color="#60a5fa"/>
          </linearGradient>
          <filter id="glow">
            <feGaussianBlur stdDeviation="6" result="coloredBlur"/>
            <feMerge>
              <feMergeNode in="coloredBlur"/>
              <feMergeNode in="SourceGraphic"/>
            </feMerge>
          </filter>
        </defs>
        <g fill="none" stroke="url(#g1)" stroke-width="4" filter="url(#glow)">
          <rect x="60" y="90" rx="22" ry="22" width="150" height="70"/>
          <rect x="310" y="90" rx="22" ry="22" width="150" height="70"/>
          <line x1="210" y1="125" x2="310" y2="125"/>
          <line x1="60" y1="125" x2="20" y2="110"/>
          <line x1="460" y1="125" x2="500" y2="110"/>
        </g>
        <circle cx="235" cy="110" r="6" fill="#4fd1c5"/>
        <g stroke="#60a5fa" stroke-width="2" fill="none" opacity="0.8">
          <path d="M235 70 C215 60, 255 60, 235 70"/>
          <path d="M235 55 C205 40, 265 40, 235 55"/>
        </g>
      </svg>
    </div>
  </div>
</header>

<nav>
  <ul>
    <li><a href="#about">About</a></li>
    <li><a href="#features">Features</a></li>
    <li><a href="#specs">Specifications</a></li>
    <li><a href="#backend">Backend</a></li>
    <li><a href="#comparison">Comparison</a></li>
    <li><a href="#impact">Impact</a></li>
  </ul>
</nav>

<section id="about">
  <h2>Project Overview</h2>
  <div class="card">
    <p>
      This project proposes an <span class="highlight">AI‑powered wearable assistive system</span> designed to enhance
      independence and safety for visually impaired individuals. The system continuously interprets
      visual surroundings using computer vision models and converts the extracted information into
      real‑time speech feedback.
    </p>
  </div>
</section>

<section id="features">
  <h2>Core Features</h2>
  <div class="grid">
    <div class="card"><h3>Real-Time Object Detection</h3><p>YOLO-based edge AI models detect obstacles, people, and objects with contextual awareness and low latency.</p></div>
    <div class="card"><h3>Text-to-Speech & OCR</h3><p>Integrated OCR reads signboards, documents, and labels aloud using efficient text-to-speech engines.</p></div>
    <div class="card"><h3>AI-Based Night Vision</h3><p>Low-light image enhancement and night-mode object detection ensure safe navigation in dark environments.</p></div>
    <div class="card"><h3>Hands-Free Wearable Design</h3><p>Ergonomic glasses frame with bone-conduction audio enables continuous assistance without blocking ambient sound.</p></div>
    <div class="card"><h3>Offline Edge AI</h3><p>On-device processing ensures privacy, reliability, and sub-200ms response time without internet dependency.</p></div>
    <div class="card"><h3>Simulation-Driven Upgradability</h3><p>AI models are validated in virtual environments, enabling safe and rapid feature upgrades.</p></div>
  </div>
</section>

<section id="specs">
  <h2>Technical Specifications</h2>
  <div class="card">
    <table>
      <tr><th>Component</th><th>Specification</th></tr>
      <tr><td>Camera Module</td><td>5MP wide-angle (120° FOV), 30fps, optimized for low-light conditions</td></tr>
      <tr><td>AI Processing Unit</td><td>Raspberry Pi 4 / Edge TPU with TensorFlow Lite inference</td></tr>
      <tr><td>Audio Output</td><td>Bone-conduction speakers for spatial audio guidance</td></tr>
      <tr><td>Battery System</td><td>3000mAh Li-Po battery, 6–8 hours continuous operation</td></tr>
      <tr><td>Frame Design</td><td>Lightweight polycarbonate ergonomic frame</td></tr>
    </table>
  </div>
</section>

<section id="backend">
  <h2>Backend & Edge-AI Architecture</h2>
  <div class="grid">
    <div class="card"><h3>On-Device AI Processing</h3><p>Real-time object detection, OCR, depth estimation, and scene understanding executed locally for privacy and low latency.</p></div>
    <div class="card"><h3>AI Development Stack</h3><p>Python 3.8+, OpenCV 4.5, YOLOv5/v8, TensorFlow Lite, and C/C++ for embedded control.</p></div>
    <div class="card"><h3>Latency Optimization</h3><p>Sub-200ms response time achieved through frame optimization, region-of-interest processing, and model quantization.</p></div>
    <div class="card"><h3>Simulation-First Validation</h3><p>Virtual testing ensures robustness across varied lighting, environments, and usage scenarios before deployment.</p></div>
  </div>
</section>

<section id="comparison">
  <h2>Market Comparison</h2>
  <div class="card">
    <table>
      <tr><th>Feature</th><th>Commercial Smart Glasses</th><th class="highlight">Our Proposed System</th></tr>
      <tr><td>Object Recognition</td><td>Basic</td><td class="highlight">Advanced Edge-AI</td></tr>
      <tr><td>Text Reading (OCR)</td><td>Limited</td><td class="highlight">High Accuracy</td></tr>
      <tr><td>Night Vision</td><td>Not Available</td><td class="highlight">AI-Based Enhancement</td></tr>
      <tr><td>Backend Processing</td><td>Mobile Dependent</td><td class="highlight">On-Device Edge AI</td></tr>
      <tr><td>Offline Functionality</td><td>No</td><td class="highlight">Yes</td></tr>
      <tr><td>Upgrade Flexibility</td><td>Fixed Features</td><td class="highlight">Simulation-Driven</td></tr>
    </table>
  </div>
</section>

<section id="impact">
  <h2>How to Use the Smart Assistive Glasses</h2>
  <div class="grid">
    <div class="card"><h3>Step 1: Wear & Power On</h3><p>User wears the glasses and powers on the device using the side-mounted control.</p></div>
    <div class="card"><h3>Step 2: Environment Capture</h3><p>The wide-angle camera continuously captures real-world surroundings.</p></div>
    <div class="card"><h3>Step 3: AI Processing</h3><p>Edge AI models analyze objects, text, distance, and lighting conditions in real time.</p></div>
    <div class="card"><h3>Step 4: Audio Guidance</h3><p>Processed information is converted into clear speech and delivered via bone-conduction audio.</p></div>
    <div class="card"><h3>Step 5: Night Mode (Optional)</h3><p>In low-light conditions, AI-based night vision enhances scene understanding automatically.</p></div>
  </div>

  <h2 style="margin-top:90px;">Cost & Practical Feasibility</h2>
  <div class="card">
    <p><span class="highlight">Prototype Cost:</span> ₹80,000 — includes high-quality edge AI hardware, camera modules, battery systems, and extensive AI model development.</p>
    <p><span class="highlight">Scaled Manufacturing Cost:</span> Estimated ₹70,000 per unit for 1000+ units through component optimization and mass production.</p>
    <p><span class="highlight">Cost Efficiency:</span> Approximately 60% cost reduction compared to existing advanced assistive wearables with similar capabilities.</p>
    <p><span class="highlight">Feasibility:</span> Built using readily available hardware and open-source AI frameworks, ensuring technical, economic, and social viability.</p>
  </div>
</section>

<section id="metrics">
  <h2>Performance Metrics & Evaluation</h2>
  <div class="grid">
    <div class="card"><h3>Detection Accuracy</h3><p>Object detection accuracy evaluated in simulation exceeds <span class="highlight">95%</span> across common indoor and outdoor scenarios.</p></div>
    <div class="card"><h3>Latency</h3><p>End-to-end response time maintained below <span class="highlight">200 ms</span> using edge inference and optimized pipelines.</p></div>
    <div class="card"><h3>Battery Endurance</h3><p>Continuous usage delivers <span class="highlight">6–8 hours</span> with adaptive power management.</p></div>
    <div class="card"><h3>Robustness</h3><p>Validated under varied lighting, motion blur, and cluttered environments using simulation-first testing.</p></div>
  </div>
</section>

<section id="ethics">
  <h2>Accessibility, Privacy & Ethics</h2>
  <div class="grid">
    <div class="card"><h3>Privacy by Design</h3><p>All vision processing occurs on-device; no images are uploaded, ensuring user privacy.</p></div>
    <div class="card"><h3>Inclusive Audio</h3><p>Bone-conduction audio preserves ambient awareness, improving safety and comfort.</p></div>
    <div class="card"><h3>Bias Mitigation</h3><p>Datasets are diversified and augmented in simulation to reduce environmental bias.</p></div>
    <div class="card"><h3>Fail-Safe Operation</h3><p>Graceful degradation ensures clear alerts even under partial system constraints.</p></div>
  </div>
</section>

<section id="roadmap">
  <h2>Future Roadmap</h2>
  <div class="grid">
    <div class="card"><h3>Short Term</h3><p>Multilingual TTS, improved night vision, and refined ergonomics.</p></div>
    <div class="card"><h3>Mid Term</h3><p>GPS-assisted navigation, scene prioritization, and haptic feedback.</p></div>
    <div class="card"><h3>Long Term</h3><p>Depth sensing, cloud-assisted updates, and federated learning for continual improvement.</p></div>
  </div>
</section>

<section id="faq">
  <h2>Frequently Asked Questions</h2>
  <div class="grid">
    <div class="card"><h3>Is a physical prototype required?</h3><p>No. A high-fidelity digital prototype with simulations is acceptable under IDTL guidelines.</p></div>
    <div class="card"><h3>Why is the prototype cost ₹80,000?</h3><p>The cost reflects research-grade hardware, edge AI components, and extensive model development.</p></div>
    <div class="card"><h3>Can it work offline?</h3><p>Yes. Edge AI enables full offline operation with low latency.</p></div>
    <div class="card"><h3>How is safety ensured?</h3><p>Low-latency audio cues, ambient-awareness audio, and fail-safe alerts enhance safety.</p></div>
  </div>
</section>

<footer>
  <p>
    AI‑Powered Smart Assistive Glasses · Innovation & Design Thinking Lab Project<br>
    Research‑oriented academic prototype
  </p>
</footer>

<script>
  // Scroll reveal micro-interaction
  const observer = new IntersectionObserver(entries => {
    entries.forEach(entry => {
      if (entry.isIntersecting) {
        entry.target.style.animation = 'fadeUp 0.9s ease forwards';
      }
    });
  }, { threshold: 0.15 });

  document.querySelectorAll('section, .card').forEach(el => observer.observe(el));
</script>
</body>
</html>
